---
header-includes:
- \usepackage{longtable}
- \usepackage[utf8]{inputenc}
- \usepackage[spanish]{babel}\decimalpoint
- \setlength{\parindent}{1.25cm}
- \usepackage{amsmath}
- \usepackage{xcolor}
- \usepackage{cancel}
- \usepackage{array}
- \usepackage{float}
- \usepackage{multirow}
output:
  pdf_document:
    number_sections: true
fontsize: 12pt
papersize: letter
geometry: margin = 1in
language: "es"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(kableExtra)
library(knitr)
library(tidyverse)
library(FactoMineR)
library(factoextra)
```

\input{titlepage}
\thispagestyle{empty}
\tableofcontents

\newpage

\pagestyle{myheadings}
\setcounter{page}{3}

\section{Introducción}

El siguiente análisis se realiza con el propósito de mostrar la gran utilidad del análisis de componentes principales (PCA) en múltiples aplicaciones estadísticas robustas
como la construcción e implementación de modelos de ML que requieren una gran cantidad de recursos computacionales. 

Para el desarrollo de este análisis, se remitirá a una base de datos relacionada con variantes rojas y blancas del vino portugués "Vinho Verde" [ref-Kaggle], en la cual se encuentran
una serie de variables que pretenden medir la calidad del vino en cuestión desde diferentes aspectos, así como una variable respuesta u "output" que define una puntuación 
final de calidad.

\subsection{Descripción de la base de datos}

Se presentan las variables de entrada a las cuales se les desea realizar en análisis de componentes principales, y la variable respuesta, que no se incluye en el PCA, pero se utilizará para la creación y validación de modelos:

\begin{table}[H]
\centering
\begin{tabular}{|>{\centering\arraybackslash}p{1cm}|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{3cm}|>{\centering\arraybackslash}p{7cm}|>{\centering\arraybackslash}p{2.2cm}|}
\hline
\textbf{No} & \textbf{Nombre}         & \textbf{Nombre en BD}      & \textbf{Descripción} & \textbf{Tipo de variable} \\ \hline
1           & Acidez fija             & fixed.acidity        & Se refiere al conjunto de los ácidos naturales procedentes de la uva (tartárico, málico, cítrico y succínico)                    & Explicativa               \\ \hline
2           & Acidez volátil          & volatile.acidity     &  La cantidad de ácido acético en el vino, que en niveles demasiado altos puede provocar un sabor desagradable a vinagre                    & Explicativa               \\ \hline
3           & Ácido cítrico           & citric.acid          &  Encontrado en pequeñas cantidades, el ácido cítrico puede agregar 'frescura' y sabor a los vinos.                    & Explicativa               \\ \hline
4           & Azúcar residual         & residual.sugar       &  La cantidad de azúcar que queda después de que se detiene la fermentación, es raro encontrar vinos con menos de 1 gramo / litro                     & Explicativa               \\ \hline
5           & Cloruros                & chlorides            &  La cantidad de sal en el vino                    & Explicativa               \\ \hline
6           & Dióxido de azufre libre & free.sulfur.dioxide  &  La forma libre de SO2 existente en equilibrio entre el SO2 molecular (como gas disuelto) y el ion bisulfito                    & Explicativa               \\ \hline
7           & Dióxido de azufre total & total.sulfur.dioxide &  Cantidad de formas libres y ligadas de SO2; En bajas concentraciones, el SO2 es mayormente indetectable en el vino.                    & Explicativa               \\ \hline
8           & Densidad                & density              &   Densidad del agua, depende del alcohol y la cantidad de azúcar utilizada                  & Explicativa               \\ \hline
9           & pH                      & pH                   & Describe qué tan ácido o básico es un vino en una escala de 0 (muy ácido) a 14 (muy básico); la mayoría de los vinos tienen entre 3 y 4                     & Explicativa               \\ \hline
10          & Sulfatos                & sulphates            & Un aditivo para el vino que puede contribuir a los niveles de dióxido de azufre (SO2), que actúa como antimicrobiano                      & Explicativa               \\ \hline
11          & Alcohol                 & alcohol              & El porcentaje de contenido de alcohol del vino                    & Explicativa               \\ \hline
12          & Calidad                 & quality              & Variable de salida (basada en datos sensoriales, puntuación entre 0 y 10)                    & Respuesta                 \\ \hline
\end{tabular}
\end{table}

\subsection{¿Por qué realizar un análisis por componentes principales?}

Se pretende conseguir una reducción en la dimensionalidad de los datos, manteniendo la mayor cantidad de información retenida posible, para posteriormente disponer de estas a la hora de crear modelos de cualquier tipo.

Es claro que a la hora de crear modelos estadísticos y computacionales tales como redes neuronales, bosques aletorios, clasificadores lineales, entre otros, el gasto computacional es alto. El uso de PCA permite realizar una \textbf{reducción en el número de variables conservando un alto porcentaje en la variabilidad de la información.} Al utilizar un menor número de variables y conservar gran parte de la variabilidad, se puede disminuir el gasto computacional de los modelos sin comprometer la calidad. 

Es bueno advertir que conocer qué variables aportan mayor variabilidad permitiría que un experto en el tema pueda descubrir más información sobre el mecanismo intrínseco del proceso.




\newpage
\section{Informe técnico}

```{r PCA1, echo=F}
#Leyendo y partiendo la BD
wine <- read.csv("winequality-red.csv", header = T)
labels <- wine[, 12]
data <- wine[, -12]

#Partiendo los datos para train y test
n <- dim(data)[1]
set.seed(123)
train_index <- sample(1:n, floor(0.8*n))
train_wine <- data[train_index, ]
test_wine <- data[-train_index, ]

#labels
train_labels <- labels[train_index]
test_label <- labels[-train_index]

#Creando PCA
wine_pca <- PCA(train_wine, graph = F, ncp = 7)

#Valores propios del PCA
eigen_wine <- get_eigenvalue(wine_pca)

#Obteniendo los individuos
individuos <- get_pca_ind(wine_pca)
variables <- get_pca_var(wine_pca)

#Screeplot
eigen_plot <- fviz_eig(wine_pca, addlabels = T)
```


Para la realización del análisis por componentes principales, se utilizó la función `PCA()` de la librería `FactoMineR`. A continuación se muestran y se comentan los resultados obtenidos.

```{r PCA2, echo=F}
colnames(eigen_wine) <- c("Eigen valores", 
                          "Porcentaje de varianza",
                          "Porcentaje de varianza acumulada")
rownames(eigen_wine) <- c("CP1", "CP2", "CP3", "CP4", "CP5", "CP6",
                          "CP7", "CP8", "CP9", "CP10", "CP11",
                          "CP12")
kable(eigen_wine, escape = F, longtable = T, booktab = T)

```

 



```{r PCA3, echo=F, fig.height=9, fig.width=7, message=F}
#Plots (Varianza acumulada y porcentaje de varianza)
#Screeplot (Porcentaje de variabilidad)
por_var <- fviz_eig(wine_pca)

#Porcentaje acumulado
cum_por <- ggplot(mapping = aes(x = 1:12, y = eigen_wine[, 3])) +
  geom_line() + xlim(1,12) +
  scale_x_continuous(breaks= 1:12) +
  geom_segment(mapping = aes(x = c(1, 8), xend = c(8, 8),
                             y = c(91.86098, 0), 
                             yend = c(91.86098, 91.86098)), 
               color = "red", linetype = "dashed")

por_var <- ggpubr::ggpar(por_var, title = "Porcentaje de variabilidad",
              xlab = "Componente principal", 
              ylab = "Porcentaje (%)")

cum_por <- ggpubr::ggpar(cum_por, title = "Variabilidad acumulada",
              xlab = "Componente principal",
              ylab = "Porcentaje (%)",
              ggtheme = theme_minimal())
ggpubr::ggarrange(por_var, cum_por, ncol = 1, nrow = 2)
```


```{r PCA4, echo=F}
#Plots de variables que mas contribuyen a las PCs
contrib_plot_pc1 <- fviz_contrib(wine_pca, choice = "var")
contrib_plot_pc2 <- fviz_contrib(wine_pca, choice = "var", axes = 2)

#Renombrando ejes y demas
contrib_plot_pc1 <- ggpubr::ggpar(contrib_plot_pc1,
  title = "Contribución de las variables a la\ncomponente principal 1", ylab = "Contribuciones (%)") 
contrib_plot_pc2 <-ggpubr::ggpar(contrib_plot_pc2,
  title = "Contribución de las variables a la\ncomponente principal 2", ylab = "Contribuciones (%)") 

ggpubr::ggarrange(contrib_plot_pc1, contrib_plot_pc2,
                  ncol = 2, nrow = 1)
```


```{r PCA5, echo=F, fig.height=9, fig.width=7}
#Circulos de correlacion
cos2_circle <- fviz_pca_var(wine_pca, repel = T, 
                            col.var = "cos2",
                            gradient.cols = c("#00AFBB",
                                              "#E7B800",
                                              "#FC4E07"))

contrib_circle <- fviz_pca_var(wine_pca, repel = T, 
                            col.var = "contrib",
                            gradient.cols = c("#00AFBB",
                                              "#E7B800",
                                              "#FC4E07"))

#Renombrando los ejes
cos2_circle <- ggpubr::ggpar(cos2_circle,
                             title = "Circulo de correlación",
                             xlab = "Componente principal 1",
                             ylab = "Componente principal 2",
                             legend.title = "Coseno cuadrado")

contrib_circle <- ggpubr::ggpar(contrib_circle,
                             title = "Circulo de correlación",
                             xlab = "Componente principal 1",
                             ylab = "Componente principal 2",
                             legend.title = "Contribución")
ggpubr::ggarrange(cos2_circle, contrib_circle, ncol = 1, nrow = 2)
```


```{r PCA6, echo=F, fig.height=9, fig.width=7}
#Plots para individuos
cos2_ind <- fviz_pca_ind(wine_pca, col.ind = "cos2",
                         gradient.cols = c("#00AFBB",
                                           "#E7B800",
                                           "#FC4E07"), 
                         repel = T,
                         select.ind = list(cos2 = 25))

contrib_ind <- fviz_pca_ind(wine_pca, col.ind = "contrib",
                            gradient.cols = c("#00AFBB",
                                              "#E7B800",
                                              "#FC4E07"), 
                            repel = T,
                            select.ind = list(contrib = 25))

#Renombrando los ejes
cos2_ind <- ggpubr::ggpar(cos2_ind,
                             title = "Gráfico de individuos",
                             xlab = "Componente principal 1",
                             ylab = "Componente principal 2",
                             legend.title = "Coseno cuadrado")

contrib_ind <- ggpubr::ggpar(contrib_ind,
                             title = "Gráfico de individuos",
                             xlab = "Componente principal 1",
                             ylab = "Componente principal 2",
                             legend.title = "Contribución")

ggpubr::ggarrange(cos2_ind, contrib_ind, ncol = 1, nrow = 2)
```


```{r PCA7, echo=F}
#En stand by
biplot <- fviz_pca_biplot(wine_pca, repel = T, 
                col.var = "#2E9FDF",
                col.ind = "#696969")
```

\newpage
```{r tabla_cor, echo=F}
#Nombres de columnas
colnames(variables$cor) <- c("CP1", "CP2", "CP3", "CP4", 
                             "CP5", "CP6", "CP7", "CP8")
#Mostrar tabla
kable(round(variables$cor, 4), escape = F, longtable = T, 
      booktab = T)
```


```{r tabla_cos2, echo=F}
#Nombres de columnas
colnames(variables$cos2) <- c("CP1", "CP2", "CP3", "CP4", 
                              "CP5", "CP6", "CP7", "CP8")
#Mostrar tabla
kable(round(variables$cos2, 4), escape = F, longtable = T, 
      booktab = T)
```

```{r tabla_contrib, echo=F}
#Nombres de columnas
colnames(variables$contrib) <- c("CP1", "CP2", "CP3", "CP4", 
                                 "CP5", "CP6", "CP7", "CP8")
#Mostrar tabla
kable(round(variables$contrib, 4), escape = F, longtable = T, 
      booktab = T)
```

```{r tabla_coord, echo=F}
#Nombres de columnas
colnames(variables$coord) <- c("CP1", "CP2", "CP3", "CP4", 
                                 "CP5", "CP6", "CP7", "CP8")
#Mostrar tabla
kable(round(variables$coord, 4), escape = F, longtable = T, 
      booktab = T)
```



```{r prohibido, echo=F, eval=F}
#NUNCA EJECUTAR NADA EN ESTE CHUNK
#Obteniendo PCs y valores propios respectivamente
#wine_pca <- PCA(data, graph = F, ncp = 154)

#Guardando wine_pca como objeto de R
#write_rds(wine_pca, "wine_pca.rds")

#Importando los individuos
# write.csv(individuos$coord, "PCA_train.csv", row.names = F)
# write.csv(train_wine, "train.csv", row.names = F)
# write.csv(matrix(train_labels, ncol = 1), 
#           "train_labels.csv", row.names = F)
# write.csv(test_wine, "test_wine.csv", row.names = F)
# write.csv(matrix(test_label, ncol = 1),
#           "test_labels.csv", row.names = F)
# 
# write.csv(predict(wine_pca, test_wine)$coord, "test_pca.csv", 
#           row.names = F)
```

\section{Ajuste de modelos y comparación}

Puesto que carece de sentido alguno realizar análisis de componentes principales sin llevar los
resultados a alguna aplicación práctica, se decide usar un modelo de machine learning para predecir
el nivel de la calidad del vino; haciendo la aclaración de que se estableció a una vino como de baja
calidad si su puntuación es no superior a cinco y de alta calidad en el caso contrario.

Dicho lo anterior, se hace necesario mencionar que el objetivo de esta sección no es otro que
comparar el rendimiento de random forest clasiffiers ajustados sobre los datos de entrenamiento
en el sistema coordenado original y en el sistema coordenado de las componentes principales.
Ambos modelos fueron ajustados usando grid search k-fold cross validation; durante este proceso
se midió la exactitud (proporción de clasificaciones realizadas de manera correcta) de ambos modelos para 
posteriormente verificar la existencia o no de diferencias significativas entre la exactitud
de estos.

Cabe aclarar que se emplearon métodos no paramétricos para contrastar las hipótesis plantedas,
a continuación se muestra el resultado de la distribución del estadístico de prueba Bootstrap.

```{r MODS, echo = F}
PCA.MOD <- read.csv("DatoscompPCA.csv")[, -c(1:2)]
NORM.MOD <- read.csv("DatoscompNorm.csv")[, -c(1:2)]
mean_train0 <- mean(PCA.MOD$mean_score_train) - mean(NORM.MOD$mean_score_train)
mean_test0 <- mean(PCA.MOD$mean_score_test) - mean(NORM.MOD$mean_score_test)
boot_mean_train <- c()
boot_mean_test <- c()
set.seed(314159)
for (i in 1:2000) {
  boot_mean_train[i] <- mean(sample(PCA.MOD$mean_score_train, 1920, replace = T)) - mean(sample(NORM.MOD$mean_score_train, 1920, replace = T))
  boot_mean_test[i] <- mean(sample(PCA.MOD$mean_score_test, 1920, replace = T)) - mean(sample(NORM.MOD$mean_score_test, 1920, replace = T))
}
pvalue_train <- 2*min(mean(boot_mean_train <= mean_train0),mean(boot_mean_train >= mean_train0))
pvalue_test <- 2*min(mean(boot_mean_test <= mean_test0),mean(boot_mean_test >= mean_test0))

histboot1 <- ggplot(data.frame(x = boot_mean_train), aes(x))+
  geom_histogram(binwidth = 0.001, col = "black", fill = "cyan")+
  labs(x = "", y = "Frecuencia",
       title = "Histograma para la diferencia de exactitud media en el conjunto de\nentrenamiento del k-fold cross validation")+
  geom_segment(data = data.frame(x = c(quantile(boot_mean_train, c(0.025, 0.975)), mean_train0),
                                 y = c(0,0,0), Clase = c("Confianza", "Confianza",
                                                       "Estadístico de prueba")),
               mapping = aes(x = x,
                             xend = x,
                             y = y, yend = c(400, 400, 400), color = Clase, linetype = Clase))+
  scale_colour_manual(values = c("black", "red"))
  
histboot2 <- ggplot(data.frame(x = boot_mean_test), aes(x))+
  geom_histogram(binwidth = 0.001, col = "black", fill = "cyan")+
  labs(x = "", y = "Frecuencia",
       title = "Histograma para la diferencia de exactitud media en el conjunto de\nprueba del k-fold cross validation")+
  geom_segment(data = data.frame(x = c(quantile(boot_mean_test, c(0.025, 0.975)), mean_test0),
                                 y = c(0,0,0), Clase = c("Confianza", "Confianza",
                                                       "Estadístico de prueba")),
               mapping = aes(x = x,
                             xend = x,
                             y = y, yend = c(400, 400, 400), color = Clase, linetype = Clase))+
  scale_colour_manual(values = c("black", "red"))


ggpubr::ggarrange(histboot1, histboot2, nrow = 2, ncol = 1)
```

Como se puede observar, el estadístico de prueba reside en el interior del intervalo
de confianza Bootstrap del 95%, por lo que no se rechaza la hipótesis de que
la exactitud media de ambos modelos es la misma.

Se reportan los p-valores de dicha prueba.

```{r pvals, echo = F}
dfpvals <- data.frame(pvalor = c(pvalue_train, pvalue_test))
rownames(dfpvals) <- c("Entrenamiento", "Prueba")
dfpvals %>%
  kable(row.names = T, col.names = "P-valor", align = "c",
        booktab = T, longtable = T) %>%
  kable_styling(position = "center")
```

Dichos p-valores son mucho mayores que el nivel de significancia usado (5%),
lo que deja en evidencia la compatibilidad entre los datos que se obtuvieron 
y la hipótesis de que no hay diferencias significativas en la exactitud media
de un modelo u otro.

Finalmente en esta sección se compara la exactitud, la precisión y la sensibilidad de ambos
modelos cuando sobre conjuntos de datos que no hicieron parte de su entrenamiento.

Antes de ello se definen los términos de precisión como el porcentaje de las predicciones
realmente correctas entre todas aquellas observaciones predichas como correctas y 
la sensibilidad como el porcentaje de predicciones que fueron hechas como correctas entre
todas aquellas que deberían haber sido clasificadas como correctas.

```{r measures, echo = F}
dfmeasures <- data.frame(norm = c("100%", "100%", "100%"),
                         pca = c("90.63%", "92.76%", "88.13%"))
rownames(dfmeasures) <- c("Exactitud", "Precisión", "Sensibilidad")

dfmeasures %>%
  kable(col.names = c("Modelo completo", "Modelo componentes principales"),
        row.names = T, align = "c", booktab = T) %>%
  kable_styling(position = "center")
```

Como se puede observar, el modelo completo funciona a la perfección con el conjunto de datos
de prueba, pues es un algoritmo bastante potente y la tarea para la que fue utilizado es bastante sencilla.
Por su parte, el modelo ajustado con las componentes principales no da un mal ajuste pues
logra predecir correctamente al rededor del 90% de las observaciones, de aquellas que predijo
como vinos de calidad realmente el 92% fueron vinos de calidad y de todos aquellos vinos
clasificados como de calidad identificó aproximadamente el 88%, dejando al modelo como 
una herramienta que no solo realiza bien su tarea sino que también como una ganancia a nivel
de coste computacional, pues su entrenamiento tarda menos tiempo debido a que se usó una menor
cantidad de variables para ajustarlo.

\section{Conclusiones}