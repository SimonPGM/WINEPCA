---
header-includes:
- \usepackage{longtable}
- \usepackage[utf8]{inputenc}
- \usepackage[spanish]{babel}\decimalpoint
- \setlength{\parindent}{1.25cm}
- \usepackage{amsmath}
- \usepackage{xcolor}
- \usepackage{cancel}
- \usepackage{array}
- \usepackage{float}
- \usepackage{multirow}
output:
  pdf_document:
    number_sections: true
fontsize: 12pt
papersize: letter
geometry: margin = 1in
language: "es"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(kableExtra)
library(knitr)
library(tidyverse)
library(FactoMineR)
library(factoextra)
```

\input{titlepage}
\thispagestyle{empty}
\tableofcontents

\newpage

\pagestyle{myheadings}
\setcounter{page}{3}

\section{Introducción}

Para dar inicio, se debe resaltar que este análisis se realiza con el propósito de mostrar la gran utilidad del PCA en múltiples aplicaciones estadísticas robustas
como la construcción e implementación de modelos de ML que requieren una gran cantidad de recursos computacionales. 

Dicho lo anterior, en este caso se remitirá a una base de datos relacionada con variantes rojas y blancas del vino portugués "Vinho Verde", en la cual se encuentran
diversas variables que pretenden medir la calidad del vino en cuestión desde diferentes aspectos, así como una variable respuesta u "output" que define una puntuación 
final de calidad.

Las variables de entrada a las cuales se les desea realizar en análisis de componentes principales se enumeran a continuación en orden de aparición en el dataset:

1. Acidez fija
2. Acidez volátil
3. Ácido cítrico
4. Azúcar residual
5. Cloruros
6. Dióxido de azufre libre 
7. Dióxido de azufre total
8. Densidad
9. Ph
10. Sulfatos
11. Alcohol 

Todas aquellas medidas en sus respectivas unidades. 

La doceava variable es la respuesta anteriormente mencionada, la cual se corresponde con la puntuación final del vino en una escala de 0 a 10.

Se pretende conseguir una reducción en la dimensionalidad de los datos, manteniendo la mayor cantidad de información retenida posible, para posteriormente 
disponer de estas a la hora de crear modelos de cualquier tipo, siendo éstos últimos en cualquier efecto, lo más parsimoniosos posible.


\newpage
\section{Informe técnico}

```{r PCA1, echo=F}
#Leyendo y partiendo la BD
wine <- read.csv("winequality-red.csv", header = T)
labels <- wine[, 12]
data <- wine[, -12]

#Partiendo los datos para train y test
n <- dim(data)[1]
set.seed(123)
train_index <- sample(1:n, floor(0.8*n))
train_wine <- wine[train_index, ]
test_wine <- wine[-train_index, ]

#labels
train_labels <- labels[train_index]
test_label <- labels[-train_index]

#Creando PCA
wine_pca <- PCA(train_wine, graph = F, ncp = 8)

#Valores propios del PCA
eigen_wine <- get_eigenvalue(wine_pca)

#Obteniendo los individuos
individuos <- get_pca_ind(wine_pca)
variables <- get_pca_var(wine_pca)

#Screeplot
eigen_plot <- fviz_eig(wine_pca, addlabels = T)
```


```{r PCA2, echo=F}
colnames(eigen_wine) <- c("Eigen valores", 
                          "Porcentaje de varianza",
                          "Porcentaje de varianza acumulada")
rownames(eigen_wine) <- c("CP1", "CP2", "CP3", "CP4", "CP5", "CP6",
                          "CP7", "CP8", "CP9", "CP10", "CP11",
                          "CP12")
kable(eigen_wine, escape = F, longtable = T, booktab = T)

```


```{r PCA3, echo=F, fig.height=9, fig.width=7, warning=F}
#Plots (Varianza acumulada y porcentaje de varianza)
#Screeplot (Porcentaje de variabilidad)
por_var <- fviz_eig(wine_pca)

#Porcentaje acumulado
cum_por <- ggplot(mapping = aes(x = 1:12, y = eigen_wine[, 3])) +
  geom_line() + xlim(1,12) +
  scale_x_continuous(breaks= 1:12) +
  geom_segment(mapping = aes(x = c(1, 8), xend = c(8, 8),
                             y = c(91.86098, 0), 
                             yend = c(91.86098, 91.86098)), 
               color = "red", linetype = "dashed")

por_var <- ggpubr::ggpar(por_var, title = "Porcentaje de variabilidad",
              xlab = "Componente principal", 
              ylab = "Porcentaje (%)")

cum_por <- ggpubr::ggpar(cum_por, title = "Variabilidad acumulada",
              xlab = "Componente principal",
              ylab = "Porcentaje (%)",
              ggtheme = theme_minimal())
ggpubr::ggarrange(por_var, cum_por, ncol = 1, nrow = 2)
```


```{r PCA4, echo=F}
#Plots de variables que mas contribuyen a las PCs
contrib_plot_pc1 <- fviz_contrib(wine_pca, choice = "var")
contrib_plot_pc2 <- fviz_contrib(wine_pca, choice = "var", axes = 2)

#Renombrando ejes y demas
contrib_plot_pc1 <- ggpubr::ggpar(contrib_plot_pc1,
  title = "Contribución de las variables a la\ncomponente principal 1", ylab = "Contribuciones (%)") 
contrib_plot_pc2 <-ggpubr::ggpar(contrib_plot_pc2,
  title = "Contribución de las variables a la\ncomponente principal 2", ylab = "Contribuciones (%)") 

ggpubr::ggarrange(contrib_plot_pc1, contrib_plot_pc2,
                  ncol = 2, nrow = 1)
```


```{r PCA5, echo=F, fig.height=9, fig.width=7}
#Circulos de correlacion
cos2_circle <- fviz_pca_var(wine_pca, repel = T, 
                            col.var = "cos2",
                            gradient.cols = c("#00AFBB",
                                              "#E7B800",
                                              "#FC4E07"))

contrib_circle <- fviz_pca_var(wine_pca, repel = T, 
                            col.var = "contrib",
                            gradient.cols = c("#00AFBB",
                                              "#E7B800",
                                              "#FC4E07"))

#Renombrando los ejes
cos2_circle <- ggpubr::ggpar(cos2_circle,
                             title = "Circulo de correlación",
                             xlab = "Componente principal 1",
                             ylab = "Componente principal 2",
                             legend.title = "Coseno cuadrado")

contrib_circle <- ggpubr::ggpar(contrib_circle,
                             title = "Circulo de correlación",
                             xlab = "Componente principal 1",
                             ylab = "Componente principal 2",
                             legend.title = "Contribución")
ggpubr::ggarrange(cos2_circle, contrib_circle, ncol = 1, nrow = 2)
```


```{r PCA6, echo=F, fig.height=9, fig.width=7}
#Plots para individuos
cos2_ind <- fviz_pca_ind(wine_pca, col.ind = "cos2",
                         gradient.cols = c("#00AFBB",
                                           "#E7B800",
                                           "#FC4E07"), 
                         repel = T,
                         select.ind = list(cos2 = 25))

contrib_ind <- fviz_pca_ind(wine_pca, col.ind = "contrib",
                            gradient.cols = c("#00AFBB",
                                              "#E7B800",
                                              "#FC4E07"), 
                            repel = T,
                            select.ind = list(contrib = 25))

#Renombrando los ejes
cos2_ind <- ggpubr::ggpar(cos2_ind,
                             title = "Gráfico de individuos",
                             xlab = "Componente principal 1",
                             ylab = "Componente principal 2",
                             legend.title = "Coseno cuadrado")

contrib_ind <- ggpubr::ggpar(contrib_ind,
                             title = "Gráfico de individuos",
                             xlab = "Componente principal 1",
                             ylab = "Componente principal 2",
                             legend.title = "Contribución")

ggpubr::ggarrange(cos2_ind, contrib_ind, ncol = 1, nrow = 2)
```


```{r PCA7, echo=F}
#En stand by
biplot <- fviz_pca_biplot(wine_pca, repel = T, 
                col.var = "#2E9FDF",
                col.ind = "#696969")
```

\newpage
```{r tabla_cor, echo=F}
#Nombres de columnas
colnames(variables$cor) <- c("CP1", "CP2", "CP3", "CP4", 
                             "CP5", "CP6", "CP7", "CP8")
#Mostrar tabla
kable(round(variables$cor, 4), escape = F, longtable = T, 
      booktab = T)
```


```{r tabla_cos2, echo=F}
#Nombres de columnas
colnames(variables$cos2) <- c("CP1", "CP2", "CP3", "CP4", 
                              "CP5", "CP6", "CP7", "CP8")
#Mostrar tabla
kable(round(variables$cos2, 4), escape = F, longtable = T, 
      booktab = T)
```

```{r tabla_contrib, echo=F}
#Nombres de columnas
colnames(variables$contrib) <- c("CP1", "CP2", "CP3", "CP4", 
                                 "CP5", "CP6", "CP7", "CP8")
#Mostrar tabla
kable(round(variables$contrib, 4), escape = F, longtable = T, 
      booktab = T)
```

```{r tabla_coord, echo=F}
#Nombres de columnas
colnames(variables$coord) <- c("CP1", "CP2", "CP3", "CP4", 
                                 "CP5", "CP6", "CP7", "CP8")
#Mostrar tabla
kable(round(variables$coord, 4), escape = F, longtable = T, 
      booktab = T)
```



```{r prohibido, echo=F, eval=F}
#NUNCA EJECUTAR NADA EN ESTE CHUNK
#Obteniendo PCs y valores propios respectivamente
#wine_pca <- PCA(data, graph = F, ncp = 154)

#Guardando wine_pca como objeto de R
#write_rds(wine_pca, "wine_pca.rds")

#Importando los individuos
#write.csv(individuos$coord, "PCA_train.csv", row.names = F)
#write.csv(train_wine, "train.csv", row.names = F)
#write.csv(matrix(train_labels, ncol = 1), 
#          "train_labels.csv", row.names = F)
#write.csv(test_wine, "test_wine.csv", row.names = F)
#write.csv(matrix(test_label, ncol = 1),
#          "test_labels.csv", row.names = F)

#write.csv(predict(wine_pca, test_wine)$coord, "test_pca.csv", 
#          row.names = F)
```

\section{Ajuste de modelos y comparación}

Puesto que carece de sentido alguno realizar análisis de componentes principales sin llevar los
resultados a alguna aplicación práctica, se decide usar un modelo de machine learning para predecir
el nivel de la calidad del vino; haciendo la aclaración de que se estableció a una vino como de baja
calidad si su puntuación es no superior a cinco y de alta calidad en el caso contrario.

Dicho lo anterior, se hace necesario mencionar que el objetivo de esta sección no es otro que
comparar el rendimiento de random forest clasiffiers ajustados sobre los datos de entrenamiento
en el sistema coordenado original y en el sistema coordenado de las componentes principales.
Ambos modelos fueron ajustados usando grid search k-fold cross validation; durante este proceso
se midió la exactitud (proporción de clasificaciones realizadas de manera correcta) de ambos modelos para 
posteriormente verificar la existencia o no de diferencias significativas entre la exactitud
de estos.

Cabe aclarar que se emplearon métodos no paramétricos para contrastar las hipótesis plantedas,
a continuación se muestra el resultado de la distribución del estadístico de prueba Bootstrap.

```{r MODS, echo = F}
PCA.MOD <- read.csv("DatoscompPCA.csv")[, -c(1:2)]
NORM.MOD <- read.csv("DatoscompNorm.csv")[, -c(1:2)]
mean_train0 <- mean(PCA.MOD$mean_score_train) - mean(NORM.MOD$mean_score_train)
mean_test0 <- mean(PCA.MOD$mean_score_test) - mean(NORM.MOD$mean_score_test)
boot_mean_train <- c()
boot_mean_test <- c()
set.seed(314159)
for (i in 1:2000) {
  boot_mean_train[i] <- mean(sample(PCA.MOD$mean_score_train, 1920, replace = T)) - mean(sample(NORM.MOD$mean_score_train, 1920, replace = T))
  boot_mean_test[i] <- mean(sample(PCA.MOD$mean_score_test, 1920, replace = T)) - mean(sample(NORM.MOD$mean_score_test, 1920, replace = T))
}
pvalue_train <- 2*min(mean(boot_mean_train <= mean_train0),mean(boot_mean_train >= mean_train0))
pvalue_test <- 2*min(mean(boot_mean_test <= mean_test0),mean(boot_mean_test >= mean_test0))

histboot1 <- ggplot(data.frame(x = boot_mean_train), aes(x))+
  geom_histogram(binwidth = 0.001, col = "black", fill = "cyan")+
  labs(x = "", y = "Frecuencia",
       title = "Histograma para la diferencia de exactitud media en el conjunto de\nentrenamiento del k-fold cross validation")+
  geom_segment(data = data.frame(x = c(quantile(boot_mean_train, c(0.025, 0.975)), mean_train0),
                                 y = c(0,0,0), Clase = c("Confianza", "Confianza",
                                                       "Estadístico de prueba")),
               mapping = aes(x = x,
                             xend = x,
                             y = y, yend = c(400, 400, 400), color = Clase, linetype = Clase))+
  scale_colour_manual(values = c("black", "red"))
  
histboot2 <- ggplot(data.frame(x = boot_mean_test), aes(x))+
  geom_histogram(binwidth = 0.001, col = "black", fill = "cyan")+
  labs(x = "", y = "Frecuencia",
       title = "Histograma para la diferencia de exactitud media en el conjunto de\nprueba del k-fold cross validation")+
  geom_segment(data = data.frame(x = c(quantile(boot_mean_test, c(0.025, 0.975)), mean_test0),
                                 y = c(0,0,0), Clase = c("Confianza", "Confianza",
                                                       "Estadístico de prueba")),
               mapping = aes(x = x,
                             xend = x,
                             y = y, yend = c(400, 400, 400), color = Clase, linetype = Clase))+
  scale_colour_manual(values = c("black", "red"))


ggpubr::ggarrange(histboot1, histboot2, nrow = 2, ncol = 1)
```

Como se puede observar, el estadístico de prueba reside en el interior del intervalo
de confianza Bootstrap del 95%, por lo que no se rechaza la hipótesis de que
la exactitud media de ambos modelos es la misma.

Se reportan los p-valores de dicha prueba.

```{r pvals, echo = F}
dfpvals <- data.frame(pvalor = c(pvalue_train, pvalue_test))
rownames(dfpvals) <- c("Entrenamiento", "Prueba")
dfpvals %>%
  kable(row.names = T, col.names = "P-valor", align = "c",
        booktab = T, longtable = T) %>%
  kable_styling(position = "center")
```

Dichos p-valores son mucho mayores que el nivel de significancia usado (5%),
lo que deja en evidencia la compatibilidad entre los datos que se obtuvieron 
y la hipótesis de que no hay diferencias significativas en la exactitud media
de un modelo u otro.

Finalmente en esta sección se compara la exactitud, la precisión y la sensibilidad de ambos
modelos cuando sobre conjuntos de datos que no hicieron parte de su entrenamiento.

Antes de ello se definen los términos de precisión como el porcentaje de las predicciones
realmente correctas entre todas aquellas observaciones predichas como correctas y 
la sensibilidad como el porcentaje de predicciones que fueron hechas como correctas entre
todas aquellas que deberían haber sido clasificadas como correctas.

```{r measures, echo = F}
dfmeasures <- data.frame(norm = c("100%", "100%", "100%"),
                         pca = c("90.63%", "92.76%", "88.13%"))
rownames(dfmeasures) <- c("Exactitud", "Precisión", "Sensibilidad")

dfmeasures %>%
  kable(col.names = c("Modelo completo", "Modelo componentes principales"),
        row.names = T, align = "c", booktab = T) %>%
  kable_styling(position = "center")
```

Como se puede observar, el modelo completo funciona a la perfección con el conjunto de datos
de prueba, pues es un algoritmo bastante potente y la tarea para la que fue utilizado es bastante sencilla.
Por su parte, el modelo ajustado con las componentes principales no da un mal ajuste pues
logra predecir correctamente al rededor del 90% de las observaciones, de aquellas que predijo
como vinos de calidad realmente el 92% fueron vinos de calidad y de todos aquellos vinos
clasificados como de calidad identificó aproximadamente el 88%, dejando al modelo como 
una herramienta que no solo realiza bien su tarea sino que también como una ganancia a nivel
de coste computacional, pues su entrenamiento tarda menos tiempo debido a que se usó una menor
cantidad de variables para ajustarlo.

\section{Conclusiones}