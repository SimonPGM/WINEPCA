---
header-includes:
- \usepackage{longtable}
- \usepackage[utf8]{inputenc}
- \usepackage[spanish]{babel}\decimalpoint
- \setlength{\parindent}{1.25cm}
- \usepackage{amsmath}
- \usepackage{xcolor}
- \usepackage{cancel}
- \usepackage{array}
- \usepackage{float}
- \usepackage{multirow}
output:
  pdf_document:
    number_sections: true
fontsize: 12pt
papersize: letter
geometry: margin = 1in
language: "es"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(kableExtra)
library(knitr)
library(tidyverse)
library(FactoMineR)
library(factoextra)
```

\input{titlepage}
\thispagestyle{empty}
\tableofcontents

\newpage

\pagestyle{myheadings}
\setcounter{page}{3}

\section{Introducción}

El siguiente análisis se realiza con el propósito de mostrar la gran utilidad del análisis de componentes principales (PCA) en múltiples aplicaciones estadísticas robustas,
como la construcción e implementación de modelos de machine learning que requieren una gran cantidad de recursos computacionales. 

Para el desarrollo de este análisis, se remitirá a una base de datos relacionada con variantes rojas y blancas del vino portugués "Vinho Verde" \cite{kaggle-bd}, en la cual se encuentran
una serie de variables que pretenden medir la calidad del vino en cuestión desde diferentes aspectos, así como una variable respuesta u "output" que define una puntuación 
final de calidad.

\newpage

\subsection{Descripción de la base de datos}

Se presentan las variables de entrada a las cuales se les desea realizar el análisis de componentes principales, y la variable respuesta, que no se incluye en el PCA, pero se utilizará para la creación y validación de modelos:

\begin{table}[H]
\centering
\begin{tabular}{|>{\centering\arraybackslash}p{1cm}|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{3cm}|>{\centering\arraybackslash}p{7cm}|>{\centering\arraybackslash}p{2.2cm}|}
\hline
\textbf{No} & \textbf{Nombre}         & \textbf{Nombre en BD}      & \textbf{Descripción} & \textbf{Tipo de variable} \\ \hline
1           & Acidez fija             & fixed.acidity        & Se refiere al conjunto de los ácidos naturales procedentes de la uva (tartárico, málico, cítrico y succínico) \cite{vino1}                   & Explicativa               \\ \hline
2           & Acidez volátil          & volatile.acidity     &  La cantidad de ácido acético en el vino, que en niveles demasiado altos puede provocar un sabor desagradable a vinagre                    & Explicativa               \\ \hline
3           & Ácido cítrico           & citric.acid          &  Encontrado en pequeñas cantidades, el ácido cítrico puede agregar 'frescura' y sabor a los vinos.                    & Explicativa               \\ \hline
4           & Azúcar residual         & residual.sugar       &  La cantidad de azúcar que queda después de que se detiene la fermentación, es raro encontrar vinos con menos de 1 gramo / litro                     & Explicativa               \\ \hline
5           & Cloruros                & chlorides            &  La cantidad de sal en el vino                    & Explicativa               \\ \hline
6           & Dióxido de azufre libre & free.sulfur.dioxide  &  La forma libre de SO2 existente en equilibrio entre el SO2 molecular (como gas disuelto) y el ion bisulfito                    & Explicativa               \\ \hline
7           & Dióxido de azufre total & total.sulfur.dioxide &  Cantidad de formas libres y ligadas de SO2; En bajas concentraciones, el SO2 es mayormente indetectable en el vino.                    & Explicativa               \\ \hline
8           & Densidad                & density              &   Densidad del agua, depende del alcohol y la cantidad de azúcar utilizada                  & Explicativa               \\ \hline
9           & pH                      & pH                   & Describe qué tan ácido o básico es un vino en una escala de 0 (muy ácido) a 14 (muy básico); la mayoría de los vinos tienen entre 3 y 4                     & Explicativa               \\ \hline
10          & Sulfatos                & sulphates            & Un aditivo para el vino que puede contribuir a los niveles de dióxido de azufre (SO2), que actúa como antimicrobiano                      & Explicativa               \\ \hline
11          & Alcohol                 & alcohol              & El porcentaje de contenido de alcohol del vino                    & Explicativa               \\ \hline
12          & Calidad                 & quality              & Variable de salida (basada en datos sensoriales, puntuación entre 0 y 10)                    & Respuesta                 \\ \hline
\end{tabular}
\end{table}

\subsection{¿Por qué realizar un análisis por componentes principales?}

Se pretende conseguir una reducción en la dimensionalidad de los datos, manteniendo la mayor cantidad de información retenida posible, para posteriormente disponer de estas a la hora de crear modelos de cualquier tipo.

Es claro que a la hora de crear modelos estadísticos y computacionales tales como redes neuronales, bosques aleatorios, clasificadores lineales, entre otros, el gasto computacional es alto. El uso de PCA permite realizar una \textbf{reducción en el número de variables conservando un alto porcentaje de la variabilidad de la información.} Al utilizar un menor número de variables y conservar gran parte de la variabilidad, se puede disminuir el gasto computacional de los modelos sin comprometer la calidad de los mismos. 

Es bueno advertir que conocer qué variables aportan mayor variabilidad permitiría que un experto en el tema pueda descubrir más información sobre el mecanismo intrínseco del proceso.




\newpage


\section{Estadística descriptiva}

\subsection{Variables sin cualidades descriptivas destacables}

Una vez iniciado el análisis descriptivo que respecta a las variables acidez fija, azúcar residual, cloruros, dióxido de azufre libre, dióxido de azufre total y pH, no se encontraron cualidades de interés que sean destacables para la construcción del presente documento, por lo cual se omite cualquier reporte sobre estas y se procede a presentar los resultados del análisis exploratorio sobre las demás variables presentes en la base de datos propuesta.


\subsection{Variables en las que se identificó un comportamiento descriptivo destacable}

```{r lodesc, echo = F}
source("Descriptive.R")
```

\subsubsection{Acidez volátil}

```{r ed1, echo=F, fig.align='center'}
boxpacidezv
```

Presentado este resultado, se puede observar que para la variable acidez volátil se manifiesta un cambio notable en su nivel medio, estando este último relacionado de manera inversa con la calidad puesto que, mientras los niveles de esta variable aumenten, la calidad del vino disminuye.

\subsubsection{Ácido cítrico}

```{r ed2, echo = F, fig.align='center'}
boxpacidocit
```

Para el ácido cítrico puede notarse que está relacionado en este caso de un modo directo con la calidad del vino, ya que para vinos clasificados en calidades más altas, los niveles de ácido cítrico son mayores. Cabe destacar además que para calidades 5 y 6 de vino, la variabilidad de la acidez cítrica es mayor.

\subsubsection{Densidad}

```{r edlastt, echo = F, fig.align='center'}
boxpdensity
```

Con esto puede observarse que en vinos de calidades mayores, la variabilidad en la densidad es mayor, comportamiento que es plausible a partir del nivel 5 de calidad en el vino.

\subsubsection{Sulfatos}

```{r edlasto, echo = F, fig.align='center'}
boxpsulfatos
```

Similarmente a como sucedió con el ácido cítrico, los sulfatos presentan una relación de directa proporcionalidad con el nivel de calidad del vino. Este comportamiento es evidente en todos los niveles presentes en el anterior gráfico, sin embargo, entre los vinos de calidad 7 y 8 no existe diferencia estadística significativa que afirme diferencia en los niveles medios de sulfatos.

\subsubsection{Alcohol}

```{r edlast, echo=F, fig.align='center'}
boxpalco
```

Por último, para el alcohol se puede apreciar que este, en términos generales, está más presente en vinos de mejores calidades, diferencia que se aprecia de una mejor manera en los niveles 6, 7 y 8 de calidad. Es también destacable que en los niveles anteriormente mencionados, incluyendo la clasificación 4 en calidad de vino, se presentan valores más dispersos de nivel de alcohol, es decir, existe mayor variabilidad de alcohol en estas calidades de bebida.

\newpage

\subsection{Normalidad}

Se realizó la prueba de normalidad de Anderson-Darlign a cada una de las
variables, obteniendo el siguente resultado.

```{r norm, echo = F}
normalidad[, -1] %>%
  kable(row.names = F, booktab = T, col.names = c("Variable", "Estadístico",
                                                  "Valor P", "Normalidad"),
        caption = "Tabla de resultados para prueba de normalidad",
        align = "c", longtable = T) %>%
  kable_styling(position = "center")
```

Como se puede apreciar en la tabla, ninguna variable posee
distribución normal y por ende se puede garantizar que en conjunto,
dichas variables no pueden poseer distribución normal multivariada.

\section{Informe técnico}

```{r PCA1, echo=F}
#Leyendo y partiendo la BD
wine <- read.csv("winequality-red.csv", header = T)
labels <- wine[, 12]
data <- wine[, -12]

#Partiendo los datos para train y test
n <- dim(data)[1]
set.seed(123)
train_index <- sample(1:n, floor(0.8*n))
train_wine <- data[train_index, ]
test_wine <- data[-train_index, ]

#labels
train_labels <- labels[train_index]
test_label <- labels[-train_index]

#Creando PCA
wine_pca <- PCA(train_wine, graph = F, ncp = 7)

#Valores propios del PCA
eigen_wine <- get_eigenvalue(wine_pca)

#Obteniendo los individuos
individuos <- get_pca_ind(wine_pca)
variables <- get_pca_var(wine_pca)

#Screeplot
eigen_plot <- fviz_eig(wine_pca, addlabels = T)
```


Para la realización del análisis por componentes principales, se utilizó la función `PCA()` de la librería `FactoMineR`. A continuación se muestran y se comentan los resultados obtenidos.

```{r PCA2, echo=F}
colnames(eigen_wine) <- c("Eigen valores", 
                          "Porcentaje de varianza",
                          "Porcentaje de varianza acumulada")
rownames(eigen_wine) <- c("CP1", "CP2", "CP3", "CP4", "CP5", "CP6",
                          "CP7", "CP8", "CP9", "CP10", "CP11")
kable(round(eigen_wine, 4), escape = F, longtable = T, booktab = T)

```

En la tabla anterior, se presentan los valores propios asociados a cada una de las componentes principales. La componente principal 1, junto con la componente principal 2, explican el `r round(eigen_wine[2, 3], 2)`\% de la variación de los datos. Para explicar el `r round(eigen_wine[7, 3], 2)`\% de la variación de los datos se requieren 7 componentes principales, esto implicaría una reducción de dimensionalidad de 11 a 7, perdiendo solo aproximadamente un 10 \% de información sobre la variabilidad de los datos. 

En los siguientes dos gráficos, se presenta la información previa visualmente: inicialmente se muestra el porcentaje de variabilidad que explica cada componente, ordenado de mayor a menor. 

Adicionalmente, se grafica el porcentaje de variabilidad acumulada, este último permite determinar visualmente cuántas componentes principales se requieren para explicar cierto porcentaje de variabilidad en los datos, además, permite dar una idea de cuánto es el aumento de variabilidad que se explica cuando se añade una componente principal.


```{r PCA3, echo=F, fig.height=9, fig.width=7, message=F, fig.align='center'}
#Plots (Varianza acumulada y porcentaje de varianza)
#Screeplot (Porcentaje de variabilidad)
por_var <- fviz_eig(wine_pca, addlabels = T, xlim = c(1, 11))

#Porcentaje acumulado
cum_por <- ggplot(mapping = aes(x = 1:11, y = eigen_wine[, 3])) +
  geom_line() + xlim(1,11) +
  scale_x_continuous(breaks= 1:11) +
  geom_segment(mapping = aes(x = c(1, 7), xend = c(7, 7),
                             y = c(90.8761, 0), 
                             yend = c(90.8761, 90.8761)), 
               color = "red", linetype = "dashed")

por_var <- ggpubr::ggpar(por_var, title = "Porcentaje de variabilidad",
              xlab = "Componente principal", 
              ylab = "Porcentaje (%)")

cum_por <- ggpubr::ggpar(cum_por, title = "Variabilidad acumulada",
              xlab = "Componente principal",
              ylab = "Porcentaje (%)",
              ggtheme = theme_minimal())
ggpubr::ggarrange(por_var, cum_por, ncol = 1, nrow = 2)
```

Teniendo en cuenta que, por definición, las componentes principales 1 y 2 son las que mayor variabilidad explican, se presenta la contribución de cada una de las variables a dichas componentes. Es bueno advertir que la contribución no es una medida de calidad, sino de magnitud. 

Para dar un ejemplo, se puede notar que relativo a la componente principal 1, las variables acidez fija, ácido cítrico, pH y densidad, tienen una contribución mayor a la promedio. 

```{r PCA4, echo=F, fig.align='center'}
#Plots de variables que mas contribuyen a las PCs
contrib_plot_pc1 <- fviz_contrib(wine_pca, choice = "var",
                                 top = 11)
contrib_plot_pc2 <- fviz_contrib(wine_pca, choice = "var", axes = 2,
                                 top = 11)

#Renombrando ejes y demas
contrib_plot_pc1 <- ggpubr::ggpar(contrib_plot_pc1,
  title = "Contribución de las variables a la\ncomponente principal 1", ylab = "Contribuciones (%)") 
contrib_plot_pc2 <-ggpubr::ggpar(contrib_plot_pc2,
  title = "Contribución de las variables a la\ncomponente principal 2", ylab = "Contribuciones (%)") 

ggpubr::ggarrange(contrib_plot_pc1, contrib_plot_pc2,
                  ncol = 2, nrow = 1)
```

Como se advirtió previamente, la contribución no es una medida de calidad. Por esta razón, es necesario utilizar una medida como los cosenos cuadrados. 

Gráficamente, una variable que esté más cerca al círculo unitario indica mayor contribución. Análogamente, una variable que forme un ángulo más pequeño con el eje respectivo de la componente principal indica mayor calidad. Esto, se traduce en que una calidad se puede considerar alta cuando el $\cos^2(\theta) \geq 0.9$.

\newpage

Haciendo uso de otra herramienta para resaltar las variables que más contribuyen a cada dimensión, se tiene el siguiente gráfico de correlación entre las variables y las componentes principales.

```{r CorrplotContrib, echo=F, fig.align='center'}
corrplot::corrplot(variables$cor, is.corr = F, outline = T, 
                   tl.col = "black")
```

\newpage

En los siguientes círculos de correlación se ilustra gráficamente las contribuciones y los cosenos cuadrados.


```{r PCA5, echo=F, fig.height=8, fig.width=7}
#Circulos de correlacion
cos2_circle <- fviz_pca_var(wine_pca, repel = T, 
                            col.var = "cos2",
                            gradient.cols = c("#00AFBB",
                                              "#E7B800",
                                              "#FC4E07")) 


contrib_circle <- fviz_pca_var(wine_pca, repel = T, 
                            col.var = "contrib",
                            gradient.cols = c("#00AFBB",
                                              "#E7B800",
                                              "#FC4E07"))

#Renombrando los ejes
cos2_circle <- ggpubr::ggpar(cos2_circle,
                             title = "Circulo de correlación",
                             xlab = "Componente principal 1",
                             ylab = "Componente principal 2",
                             legend.title = "Coseno cuadrado")

# Anotaciones cos2
cos2_circle_anot <- cos2_circle + 
    annotate(
    geom = "curve", x = 0.3, y = 0.9, xend = 0.55, yend = 1, 
    colour = "blue",
    curvature = -.3, arrow = arrow(length = unit(2, "mm"))
  ) + 
  annotate(geom = "text", x = 0.56, y = 0.9, label = "Alta contribución \n Alta calidad \n Respecto \n a la CP2", hjust = "left", size = 3) +
  annotate(
    geom = "curve", x = -0.4, y = 0.42, xend = -0.75, yend = 0.52, 
    colour = "blue",
    curvature = 0.1, arrow = arrow(length = unit(2, "mm"))
    ) +
  annotate(geom = "text", x = -0.51, y = 0.76, label = "Baja calidad \n respecto a \n ambas \n componentes ", hjust = "right", size = 3) + 
  annotate(
    geom = "curve", x = -0.75, y = -0.05, xend = -0.5, yend = -0.25, 
    colour = "blue",
    curvature = -.3, arrow = arrow(length = unit(2, "mm"))
  ) +
  annotate(geom = "text", x = -0.55, y = -0.56, label = "Alta calidad \n respecto a CP1. \n Calidad cercana \n a cero respecto a \n CP2", hjust = "center", size = 3)


contrib_circle <- ggpubr::ggpar(contrib_circle,
                             title = "Circulo de correlación",
                             xlab = "Componente principal 1",
                             ylab = "Componente principal 2",
                             legend.title = "Contribución")
ggpubr::ggarrange(cos2_circle_anot, contrib_circle, ncol = 1, nrow = 2)
```

De estos círculos de correlación se puede apreciar que, para la primera componente principal, las variables acidez fija, acidez cítrica y pH son las que más contribuyen y ayudan a representar mejor dicha componente.

Ahora, para la segunda componente principal se presenta un caso similar, pero esta vez con las variables dióxido de azufre total y libre, puesto que, estas dos son las que mayor longitud de proyección y menor ángulo respecto a dicha componente principal presentan. 

A continuación, se muestra el mapeo en las componentes principales 1 y 2 para los 25 individuos con mayor coseno cuadrado y con mayor contribución, respectivamente. A cada individuo se le asigna un valor en una escala de color, correspondiende a la medida en cuestión. 

```{r PCA6, echo=F}
#Plots para individuos
cos2_ind <- fviz_pca_ind(wine_pca, col.ind = "cos2",
                         gradient.cols = c("#00AFBB",
                                           "#E7B800",
                                           "#FC4E07"), 
                         repel = T,
                         select.ind = list(cos2 = 25))

contrib_ind <- fviz_pca_ind(wine_pca, col.ind = "contrib",
                            gradient.cols = c("#00AFBB",
                                              "#E7B800",
                                              "#FC4E07"), 
                            repel = T,
                            select.ind = list(contrib = 25))

#Renombrando los ejes
cos2_ind <- ggpubr::ggpar(cos2_ind,
                             title = "Gráfico de individuos",
                             xlab = "Componente principal 1",
                             ylab = "Componente principal 2",
                             legend.title = "Coseno cuadrado")

#Anotaciones
cos2_ind_ano <- cos2_ind + 
                  geom_vline(xintercept = wine_pca[["ind"]][["coord"]]["147",1], color = "red", linetype = "dotted") +
                  geom_hline(yintercept = wine_pca[["ind"]][["coord"]]["147",2], color = "red", linetype = "dotted") +
                  annotate(
                    geom = "curve", 
                    x = wine_pca[["ind"]][["coord"]]["147",1] + 0.03, 
                    y = wine_pca[["ind"]][["coord"]]["147",2] - 0.03, xend = -2, yend = 1, 
                    colour = "blue",
                    curvature = -.3, arrow = arrow(length = unit(2, "mm"))
                  ) +
                  annotate(geom = "text", x = -2, y = 0.6, label = "Observación 147 \n en el nuevo \n sistema de \n coordenadas", hjust = "center", size = 3)

contrib_ind <- ggpubr::ggpar(contrib_ind,
                             title = "Gráfico de individuos",
                             xlab = "Componente principal 1",
                             ylab = "Componente principal 2",
                             legend.title = "Contribución")

#ggpubr::ggarrange(cos2_ind_ano, contrib_ind, ncol = 1, nrow = 2)
cos2_ind_ano
contrib_ind
```

```{r PCA7, echo=F}
#En stand by
biplot <- fviz_pca_biplot(wine_pca, repel = T, 
                col.var = "#2E9FDF",
                col.ind = "#696969")
```

En las siguientes tablas se presenta de forma numérica los resultados más relevantes para el PCA: 

```{r tabla_cor, echo=F}
#Nombres de columnas
colnames(variables$cor) <- c("CP1", "CP2", "CP3", "CP4", 
                             "CP5", "CP6", "CP7")
#Mostrar tabla
kable(round(variables$cor, 4), escape = F, longtable = T, 
      booktab = T, 
      caption = "Coordenadas")  %>%
      kable_styling(latex_options = c("hold_position", "repeat_header"))
```


```{r tabla_cos2, echo=F}
#Nombres de columnas
colnames(variables$cos2) <- c("CP1", "CP2", "CP3", "CP4", 
                              "CP5", "CP6", "CP7")
#Mostrar tabla
kable(round(variables$cos2, 4), escape = F, longtable = T, 
      booktab = T, 
      caption = "Cosenos cuadrados")  %>%
      kable_styling(latex_options = c("hold_position", "repeat_header"))
```

```{r tabla_contrib, echo=F}
#Nombres de columnas
colnames(variables$contrib) <- c("CP1", "CP2", "CP3", "CP4", 
                                 "CP5", "CP6", "CP7")
#Mostrar tabla
kable(round(variables$contrib, 4), escape = F, longtable = T, 
      booktab = T, 
      caption = "Contribuciones")  %>%
      kable_styling(latex_options = c("hold_position", "repeat_header"))
```

\newpage

```{r tabla_coord, echo=F}
#Nombres de columnas
colnames(variables$coord) <- c("CP1", "CP2", "CP3", "CP4", 
                                 "CP5", "CP6", "CP7")
#Mostrar tabla
kable(round(variables$coord, 4), escape = F, longtable = T, 
      booktab = T,
      caption = "Correlaciones")  %>%
      kable_styling(latex_options = c("hold_position", "repeat_header"))
```

```{r prohibido, echo=F, eval=F}
#NUNCA EJECUTAR NADA EN ESTE CHUNK
#Obteniendo PCs y valores propios respectivamente
#wine_pca <- PCA(data, graph = F, ncp = 154)

#Guardando wine_pca como objeto de R
#write_rds(wine_pca, "wine_pca.rds")

#Importando los individuos
# write.csv(individuos$coord, "PCA_train.csv", row.names = F)
# write.csv(train_wine, "train.csv", row.names = F)
# write.csv(matrix(train_labels, ncol = 1), 
#           "train_labels.csv", row.names = F)
# write.csv(test_wine, "test_wine.csv", row.names = F)
# write.csv(matrix(test_label, ncol = 1),
#           "test_labels.csv", row.names = F)
# 
# write.csv(predict(wine_pca, test_wine)$coord, "test_pca.csv", 
#           row.names = F)
```

\section{Ajuste de modelos y comparación}

Puesto que carece de sentido alguno realizar análisis de componentes principales 
sin llevar los resultados a alguna aplicación práctica, se decide usar un modelo 
de machine learning para predecir el nivel de la calidad del vino. Esto
se realiza a través de separar los datos en conjuntos de entrenamiento y prueba,
tanto en los datos en su espacio original como los transformados a través del
análisis de componentes principales para ajustar un modelo en cada espacio
con su respectivo conjunto de entrenamiento.

Dicho lo anterior, se hace necesario mencionar que el objetivo de esta sección no
es otro que comparar el rendimiento de los modelos de regresión de bosque 
aleatorio ajustados sobre los datos de entrenamiento en el sistema coordenado 
original y en el sistema coordenado de las componentes principales.

Ambos modelos fueron ajustados usando grid search k-fold cross validation; durante
este proceso se tomaron medidas de la raíz del error cuadrático medio (RMSE) de 
ambos modelos para posteriormente verificar la existencia o no de diferencias 
significativas entre el RMSE de estos.

Cabe aclarar que se emplearon métodos no paramétricos para contrastar las hipótesis plantedas, además, dado que se realizó k-fold cross validation, se
tienen valores del RMSE para conjuntos de entrenamiento y prueba gracias
a la naturaleza del proceso de validación utilizado.

\newpage 

A continuación se muestra el resultado de la distribución del estadístico de prueba Bootstrap.

```{r MODS, echo = F}
PCA.MOD <- read.csv("DatoscompPCA.csv")[, -1]
NORM.MOD <- read.csv("DatoscompNorm.csv")[, -1]
mean_train0 <- mean(PCA.MOD$mean_score_train) - mean(NORM.MOD$mean_score_train)
mean_test0 <- mean(PCA.MOD$mean_score_test) - mean(NORM.MOD$mean_score_test)
boot_mean_train <- c()
boot_mean_test <- c()
set.seed(314159)
for (i in 1:2000) {
  boot_mean_train[i] <- mean(sample(PCA.MOD$mean_score_train, 1920, replace = T)) - mean(sample(NORM.MOD$mean_score_train, 1920, replace = T))
  boot_mean_test[i] <- mean(sample(PCA.MOD$mean_score_test, 1920, replace = T)) - mean(sample(NORM.MOD$mean_score_test, 1920, replace = T))
}
pvalue_train <- 2*min(mean(boot_mean_train <= mean_train0),mean(boot_mean_train >= mean_train0))
pvalue_test <- 2*min(mean(boot_mean_test <= mean_test0),mean(boot_mean_test >= mean_test0))

histboot1 <- ggplot(data.frame(x = boot_mean_train), aes(x))+
  geom_histogram(binwidth = 5e-4, col = "black", fill = "cyan")+
  labs(x = "", y = "Frecuencia",
       title = "Histograma para la diferencia del RMSE medio en el conjunto de\nentrenamiento del k-fold cross validation")+
  geom_segment(data = data.frame(x = c(quantile(boot_mean_train, c(0.025, 0.975)), mean_train0),
                                 y = c(0,0,0), Clase = c("Confianza", "Confianza",
                                                       "Estadístico de prueba")),
               mapping = aes(x = x,
                             xend = x,
                             y = y, yend = c(600, 600, 600), color = Clase, linetype = Clase))+
  scale_colour_manual(values = c("black", "red"))
  
histboot2 <- ggplot(data.frame(x = boot_mean_test), aes(x))+
  geom_histogram(binwidth = 5e-4, col = "black", fill = "cyan")+
  labs(x = "", y = "Frecuencia",
       title = "Histograma para la diferencia del RMSE medio en el conjunto de\nprueba del k-fold cross validation")+
  geom_segment(data = data.frame(x = c(quantile(boot_mean_test, c(0.025, 0.975)), mean_test0),
                                 y = c(0,0,0), Clase = c("Confianza", "Confianza",
                                                       "Estadístico de prueba")),
               mapping = aes(x = x,
                             xend = x,
                             y = y, yend = c(600, 600, 600), color = Clase, linetype = Clase))+
  scale_colour_manual(values = c("black", "red"))


ggpubr::ggarrange(histboot1, histboot2, nrow = 2, ncol = 1)
```

Como se puede observar, el estadístico de prueba reside en el interior del
intervalo de confianza Bootstrap del 95%, por lo que no se rechaza la hipótesis de
que el RMSE  medio de ambos modelos es el mismo para el conjunto de entrenamiento y el de prueba durante el proceso de grid search k-fold cross validation.

Se reportan los p-valores de dicha prueba.

```{r pvals, echo = F}
dfpvals <- data.frame(pvalor = c(pvalue_train, pvalue_test))
rownames(dfpvals) <- c("Entrenamiento", "Prueba")
dfpvals %>%
  kable(row.names = T, col.names = "P-valor", align = "c",
        booktab = T, longtable = T) %>%
  kable_styling(position = "center")
```

Dichos p-valores son mucho mayores que el nivel de significancia usado (5%),
lo que deja en evidencia la compatibilidad entre los datos que se obtuvieron 
y la hipótesis de que no hay diferencias significativas en el RMSE medio
de un modelo u otro. De hecho, el hecho de que los p-valores resulten
tan cercanos a 1 evidencia una fuerte concordancia entre la igualdad de las medias
de la distribución Bootstrap del estadístico de prueba.

Finalmente en esta sección se comparan ambos modelos cuando predicen sobre conjuntos de datos que no hicieron parte de su entrenamiento. Para esto se
toman la raíz del error cuadrático medio (RMSE), la desviación absoluta de 
la media (MAE) y la desviación absoluta porcentual de la media (MAPE).

\newpage

```{r measures, echo = F}
dfmeasures <- read.csv("Compfinal.csv", row.names = 1)

dfmeasures %>% round(4) %>%
  mutate(Porcentaje_de_error = paste(as.character(Porcentaje_de_error), "%",
                                     sep = "")) %>%
  kable(col.names = c("Modelo completo",
                      "Modelo componentes principales",
                      "Porcentaje de error"),
        row.names = T, align = "c", booktab = T,
        longtable = T) %>%
  kable_styling(position = "center")
```

Como se puede observar, el modelo completo obtiene valores más pequeños
en las medidas anteriormente descritas cuando predice sobre el conjunto de prueba, sin embargo el modelo ajustado usando los datos de prueba llevados al espacio
de las componentes principales también obtiene medidas muy bajas, de hecho
en todas ellas posee un error relativo porcentual no mayor a 6.4%, por lo que
presenta un rendimiento muy similar al modelo original.

Así que al considerar las conclusiones de la prueba Bootstrap (no existen
diferencias significativas entre los rendimientos del modelo al predecir)
y la tabla, se puede aseverar con total tranquilidad que el modelo ajustado
con los datos en el espacio de las componentes principales es igual de bueno
que el ajustado sobre los datos en su espacio original, a pesar
de que el primero contenía un conjunto que explicaba el 90% de la variabilidad
total del conjunto original. Adicionalmente, se tiene una ganancia a nivel de coste
computacional pues al tener menos columnas, el número de operaciones
que debe realizar el software para ajustar modelos es menor y por ende esto
desemboca en un proceso más rápido y eficiente.

\newpage

\section{Conclusiones}

\begin{itemize}
\item Concretizando, como se vio en el apartado del informe técnico, fueron necesarias 7 covariables para explicar el 90.88\% de la variación de los datos, por lo cual, se obtiene una reducción considerable en la dimensionalidad del sistema, resultado deseable para el propósito de este proyecto. 

\item En segundo lugar se tiene una alta influencia de las variables relacionadas con la acidez a la hora de explicar la componente principal 1, dichas variables se encuentran correlacionadas  de manera fuerte con el pH, el cual es una medida de acidez. 

\item Dado el ángulo y la norma de la variable acidez fija, se puede afirmar que esta es la que mejor explica la componente principal 1, seguida a su vez de la variable ácido cítrico. Cabe destacar también que el pH aporta gran calidad a esta componente porque aunque su longitud en el circulo de correlación no es tan alta como la de las variables anteriores, su ángulo respecto al eje formado por dicha componente es mínimo.

\item Las variables relacionadas con dioxido de azufre son las que explican de mejor manera la componente principal 2, adicionalmente son aquellas con mejor calidad de representación en dicha componente porque el ángulo que forman con dicho eje es pequeño y tienen una gran magnitud. Además están altamente correlacionadas.

\item Finalmente, respecto a la implementación de los modelos descritos anteriormente, se puede afirmar que el análisis de componentes principales para esa causa fue de gran provecho, puesto que, como se mostró en los respectivos resultados, el modelo ajustado con el conjunto completo de covariables tiene un rendimiento similar al modelo con componentes principales, a pesar de que éste último explica aproximadamente el 91\% de la variabilidad total de los datos originales, y además ganando terreno en términos de parsimonia y eficiencia computacional.

\end{itemize}

\newpage

\bibliographystyle{ieeetr}
\bibliography{bibliografia}